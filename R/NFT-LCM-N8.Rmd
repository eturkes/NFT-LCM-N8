---
title: "NFT LCM N8 Analysis"
knit: (function(inputFile, encoding) {
  rmarkdown::render(
    inputFile,
    encoding = encoding,
    output_file = file.path("..", "results", "NFT_LCM_N8.html")
  )})
---

# Data Cleaning and Prep

In this section, the raw data is read into R and manipulated as necessary to create a `SummarizedExperiment` object for use with the `DEP` package.

```{r}
#    This file is part of NFT-LCM-N8.
#    Copyright (C) 2024  Emir Turkes, Martha Foiani, Claire Frodsham, UK
#    DRI at UCL
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

# Best way to load a bunch of packages without tons of messages being produced.
# -----------------------------------------------------------------------------
library(conflicted)
packages <- c(
  "DEP", "SummarizedExperiment", "plotly", "limma", "dplyr", "DT",
  "ComplexHeatmap", "colorRamp2", "RColorBrewer", "tibble", "scales"
)
invisible(suppressPackageStartupMessages(lapply(packages, FUN = library, character.only = TRUE)))
# -----------------------------------------------------------------------------

`%notin%` <- Negate(`%in%`) # Add custom function.

knitr::opts_chunk$set(dpi = 300, fig.width = 12, fig.height = 8) # Produce high-quality images with better sizes.

data <- read.delim(file.path("..", "data", "report.pg_matrix.tsv")) # Read in data.

# Use some regex magic to tidy up sample names.
# ---------------------------------------------
colnames(data) <- sub("^.*?([0-9]+_[^_]+_[0-9]+_[^_]+).*", replacement = "\\1", x = colnames(data))
colnames(data) <- c(colnames(data)[1:5], paste0("Donor", colnames(data)[6:60]))
colnames(data) <- c(
  colnames(data)[1:5], sub("(.*_){1}(\\d+)_.+", replacement = "\\1TechRep\\2", colnames(data)[6:60])
)
# ---------------------------------------------

# Remove proteins that do not have a gene annotation.
# ---------------------------------------------------
remove <- which(data$Genes == "")
if (length(remove > 0)) { # Need to check that "remove" is non-empty.
  data <- data[-remove, ]
}
# ---------------------------------------------------

# Adds "name" and "id" columns to end of the data frame that contain one gene and protein name per row, as
# opposed to several semicolon delimited entries as seen in the "Genes" and "Protein.Ids" columns.
# --------------------------------------------------------------------------------------------------------
data <- make_unique(data, names = "Genes", ids = "Protein.Ids")
# --------------------------------------------------------------------------------------------------------

# Create a data frame for metadata.
# "label", "condition", and "replicate" are required for the DEP package.
# -----------------------------------------------------------------------
experimental_design <- data.frame(
  label = colnames(data)[6:60],
  condition = sub("^[^_]*_([^_]*).*", replacement = "\\1", colnames(data)[6:60]),
  techrep = sub(".*_", replacement = "", colnames(data)[6:60]),
  donor = sub("_.*", replacement = "", colnames(data)[6:60])
)
experimental_design$replicate <- paste(experimental_design$donor, experimental_design$techrep, sep = "_")
# -----------------------------------------------------------------------

# Create SummarizedExperiment object for use with DEP.
# ----------------------------------------------------
data <- make_se(data, columns = 6:60, expdesign = experimental_design)
data_bak <- data # Make a copy of unprocessed data for later.
# ----------------------------------------------------
```

# Preprocessing

Basic QC visualisations are shown here and the data is normalised and imputed, using standard methods.

```{r}
hist(assay(data), n = 100) # Visualise data distribution.

# Various plotting methods to assess missing values.
# --------------------------------------------------
plot_numbers(data)
plot_frequency(data)
plot_detect(data)
plot_missval(data)
# --------------------------------------------------

# Must remove samples where no proteins at all were detected.
# -----------------------------------------------------------
remove <- which(colSums(assay(data), na.rm = TRUE) == 0)
if (length(remove > 0)) {
  data <- data[ , -remove]
}
# -----------------------------------------------------------

# Normalise data using a variance stabilising transformation (VSN).
# -----------------------------------------------------------------
orig <- data # Make a copy of the pre-normalised data for plotting later.
data <- normalize_vsn(data)
meanSdPlot(data)
plot_normalization(orig)
plot_normalization(data)
# -----------------------------------------------------------------

# Impute data using the k-nearest neighbors algorithmn (KNN).
# -----------------------------------------------------------
orig <- data
data <- impute(data, fun = "knn", colmax = 100)
plot_imputation(orig, data)
# -----------------------------------------------------------

rm(orig) # Remove temporary objects.
```

# PCA

Create PCA plots for the data.
The plots have interactive features when moused-over.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Subsetting

Subset the data to those samples that group together on the basis of missing fewer values.

```{r}
keep <- rownames(df[which(df$PC1 < 0 & df$PC2 > 0), ]) # Top left of PCA seems to have highest quality results.
data_bak_sub <- data_bak[ , keep] # Use unprocessed copy to visualise missing values.

plot_numbers(data_bak_sub)

remove <- which(data_bak_sub$donor == "Donor9") # Remove Donor9 because there are no good tangle-neg. samples.
data_bak_sub <- data_bak_sub[ , -remove]

plot_numbers(data_bak_sub)

# Apply subsetting to the processed dataset.
# ------------------------------------------
data <- data[ , keep]
data <- data[ , -remove]
# ------------------------------------------
```

# PCA

Create more PCA plots after subsetting.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Reprocessing

We start with the unprocessed data again, this time with the low-quality samples removed in order to achieve better preprocessing.
We also apply a more sophisticated imputation pipeline.

```{r}
#' Custom version of \code{plot_detect} from DEP which attempts to plot the intersection at which
#' MNAR becomes MAR.
#'
#' \code{plot_detect_custom} generates density and CumSum plots
#' of protein intensities with and without missing values
#'
#' @param se SummarizedExperiment,
#' Data object with missing values.
#' @return Density and CumSum plots of intensities of
#' proteins with and without missing values
#' (generated by \code{\link[ggplot2]{ggplot}}).
#' @examples
#' # Load example
#' data <- UbiLength
#' data <- data[data$Reverse != "+" & data$Potential.contaminant != "+",]
#' data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")
#'
#' # Make SummarizedExperiment
#' columns <- grep("LFQ.", colnames(data_unique))
#' exp_design <- UbiLength_ExpDesign
#' se <- make_se(data_unique, columns, exp_design)
#'
#' # Filter
#' filt <- filter_missval(se, thr = 0)
#'
#' # Plot intensities of proteins with missing values
#' plot_detect_custom(filt)
#' @export
plot_detect_custom <- function(se, elbow = FALSE, threshold = 0.35) {
  # Show error if inputs are not the required classes
  assertthat::assert_that(inherits(se, "SummarizedExperiment"))

  se_assay <- assay(se)
  # Show error if there are no missing values
  if(!any(is.na(se_assay))) {
    stop("No missing values in '", deparse(substitute(se)), "'",
         call. = FALSE)
  }

  # Get a long data.frame of the assay data annotated with sample info
  df <- se_assay %>%
    data.frame() %>%
    rownames_to_column() %>%
    tidyr::gather(ID, val, -rowname)

  # Get a summarized table with mean protein intensities and
  # indication whether the protein has missing values
  stat <- df %>%
    group_by(rowname) %>%
    summarize(mean = mean(val, na.rm = TRUE), missval = any(is.na(val)))

  # Calculate cumulative fraction
  cumsum <- stat %>%
    group_by(missval) %>%
    arrange(mean) %>%
    mutate(num = 1, cs = cumsum(num), cs_frac = cs/n())

  # Create a stacked probability density plot instead of the usual plots.
  # ---------------------------------------------------------------------
  color <- c("#74A9CF", "#045A8D")
  p <- ggplot(stat, aes(mean, ..count.., fill = missval, color = missval)) +
    geom_density(position = "fill") +
    scale_x_continuous(expression(log[2]~"Intensity"), expand = c(0, 0), n.breaks = 10) +
    scale_y_continuous("Relative proportion", labels = percent, expand = c(0, 0), n.breaks = 10) +
    theme_DEP1() +
    scale_color_manual("Missing values", values = color) +
    scale_fill_manual("Missing values", values = color)
  # ---------------------------------------------------------------------

  if (elbow == TRUE) {

    # Extract X and Y values of the curve.
    # ------------------------------------
    p_build <- ggplot_build(p)
    x <- p_build$data[[1]]$x
    y <- p_build$data[[1]]$y
    # ------------------------------------

    # Find "elbow" points of the curve.
    # The method is adapted from content on Stack Overflow.
    # https://stackoverflow.com/questions/41518870/finding-the-elbow-knee-in-a-curve/
    # Question asked by: dan https://stackoverflow.com/users/5548896/dan
    # Answer given by: Sandipan Dey https://stackoverflow.com/users/4706171/sandipan-dey
    # ----------------------------------------------------------------------------------
    d1 <- diff(y) / diff(x)
    d2 <- diff(d1) / diff(x[-1])
    idx <- which(abs(d2) > threshold)
    # ----------------------------------------------------------------------------------

    # Add cutoff line at the minimum elbow point to the plot.
    # -------------------------------------------------------
    p <- p + geom_vline(xintercept = min(x[idx]))
    # -------------------------------------------------------
  }
  p
}

data <- data_bak_sub # Make the main data object the unprocessed version.

hist(assay(data), n = 100) # Visualise data distribution.

# Various plotting methods to assess missing values.
# --------------------------------------------------
plot_numbers(data)
plot_frequency(data)
plot_detect(data)
plot_missval(data)
# --------------------------------------------------

# Replace proteins missing entirely in a condition with minimum value per condition in random
# samples.
# -------------------------------------------------------------------------------------------
for (condition in unique(data$condition)) {
  min <- min(assay(data)[ , which(data$condition == condition)], na.rm = TRUE)
  replace <- which(is.na(rowMeans(assay(data)[ , which(data$condition == condition)], TRUE)))
  set.seed(1)
  col <- sample(which(data$condition == condition), length(replace), TRUE)
  for (i in seq_along(replace)) {
    assay(data)[replace[i], col[i]] <- min
  }
}
# -------------------------------------------------------------------------------------------

# Find intensity cutoff point at which MNAR becomes MAR by finding the inflection point of intensity
# where the proportion of proteins with missing values dramatically level off.
# We do this separately for each condition.
# --------------------------------------------------------------------------------------------------
plot <- plot_detect_custom(data[ , which(data$condition == "Neg")])
plot_data <- ggplot_build(plot)
Neg_MNAR_cutoff <- 12.4
cat(paste0("For Neg.\nCutoff at ", Neg_MNAR_cutoff))
plot + geom_vline(xintercept = Neg_MNAR_cutoff) + ggtitle("Neg")

plot <- plot_detect_custom(data[ , which(data$condition == "Pos")])
plot_data <- ggplot_build(plot)
Pos_MNAR_cutoff <- 12.4
cat(paste0("For Pos.\nCutoff at ", Pos_MNAR_cutoff))
plot + geom_vline(xintercept = Pos_MNAR_cutoff) + ggtitle("Pos")
# --------------------------------------------------------------------------------------------------

# Order each condition by row means and select the last protein to be included as MNAR.
# We choose row means over medians because high expression outliers may be decent indication a
# protein is not MNAR.
# --------------------------------------------------------------------------------------------
Neg_order <- order(rowMeans(assay(data)[ , which(data$condition == "Neg")], TRUE))
data <- data[Neg_order, ]
Neg_MNAR <- names(
  which(rowMeans(assay(data)[ , which(data$condition == "Neg")], TRUE) < Neg_MNAR_cutoff)
)

Pos_order <- order(rowMeans(assay(data)[ , which(data$condition == "Pos")], TRUE))
data <- data[Pos_order, ]
Pos_MNAR <- names(
  which(rowMeans(assay(data)[ , which(data$condition == "Pos")], TRUE) < Pos_MNAR_cutoff)
)
# --------------------------------------------------------------------------------------------

# In each condition, remove MAR (non-MNAR) proteins where the majority are missing.
# Generally, we have found that MAR imputation with a majority of missing values leads to suspect
# imputation.
# MNAR imputation however, does not seem to suffer from this limitation, and in fact it is logical
# that MNAR proteins would have a high number of missing values.
# ------------------------------------------------------------------------------------------------
Neg_data <- data[ , which(data$condition == "Neg")]
Neg_data <- Neg_data[rownames(Neg_data) %notin% Neg_MNAR, ]
missing_data <- assay(Neg_data) %>% data.frame(.)
missing_data <- ifelse(is.na(missing_data), 0, 1)
discard <- which(rowSums(missing_data, TRUE) < 5) # TODO: Automate this.
if (length(discard) > 0) {
  Neg_data <- Neg_data[-discard, ]
}
print(paste0("Removed ", length(discard), " proteins from Neg group."))

Pos_data <- data[ , which(data$condition == "Pos")]
Pos_data <- Pos_data[rownames(Pos_data) %notin% Pos_MNAR, ]
missing_data <- assay(Pos_data) %>% data.frame(.)
missing_data <- ifelse(is.na(missing_data), 0, 1)
discard <- which(rowSums(missing_data, TRUE) < 5) # TODO: Automate this.
if (length(discard) > 0) {
  Pos_data <- Pos_data[-discard, ]
}
print(paste0("Removed ", length(discard), " proteins from Pos group."))
# ------------------------------------------------------------------------------------------------

# In order to ensure that all conditions have MAR proteins with majority non-missing values, we
# perform the unions below.
# For example, out of the proteins that pass this QC in one condition, or have no missing values, we
# only keep those that pass this QC, have no missing values, or are MNAR in all other conditions as
# well.
# --------------------------------------------------------------------------------------------------
Neg_MAR <- rownames(Neg_data)[
  rownames(Neg_data) %in% Pos_MNAR | rownames(Neg_data) %in% rownames(Pos_data)
]
Pos_MAR <- rownames(Pos_data)[
  rownames(Pos_data) %in% Neg_MNAR | rownames(Pos_data) %in% rownames(Neg_data)
]

rm(Neg_data, Pos_data)
MAR <- unique(append(Neg_MAR, Pos_MAR))

Neg_MNAR_passQC <- Neg_MNAR[Neg_MNAR %in% Pos_MAR]
Pos_MNAR_passQC <- Pos_MNAR[Pos_MNAR %in% Neg_MAR]

MNAR <- unique(append(Neg_MNAR_passQC, Pos_MNAR_passQC))
# --------------------------------------------------------------------------------------------------

# We join MAR and MNAR lists and subset the data.
# -----------------------------------------------
keep <- unique(append(MAR, MNAR))
data <- data[rownames(data) %in% keep, ]
# -----------------------------------------------

# Normalise data using a variance stabilising transformation (VSN).
# -----------------------------------------------------------------
orig <- data # Make a copy of the pre-normalised data for plotting later.
data <- normalize_vsn(data)
meanSdPlot(data)
plot_normalization(orig)
plot_normalization(data)
# -----------------------------------------------------------------

# The main imputation code for normalised data.
# ---------------------------------------------
orig <- data

impute1 <- data[ , which(data$condition == "Neg")]
impute_vector <- rownames(impute1) %in% Neg_MNAR # Logical vector specifying MNAR.
set.seed(1)
impute1 <- impute(impute1, "mixed", randna = !impute_vector, mar = "knn", mnar = "MinProb")

impute2 <- data[ , which(data$condition == "Pos")]
impute_vector <- rownames(impute2) %in% Pos_MNAR
set.seed(1)
impute2 <- impute(impute2, "mixed", randna = !impute_vector, mar = "knn", mnar = "MinProb")

data <- data[ , match(c(colnames(impute1), colnames(impute2)), colnames(data))]
assay(data, withDimnames = FALSE) <- cbind(assay(impute1), assay(impute2))

plot_imputation(orig, data)
# ---------------------------------------------

rm(orig) # Remove temporary objects.
```

# PCA

Create more PCA plots with the reprocessed data.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Differential Abundance

We test for differential expression between tangle-positive and tangle-negative samples.
In order to account to technical replication, we include a custom version of the `test_diff` function from DEP.
We also include a custom version of `datatable` from DT, which allows downloading of the data.

```{r}
design <- model.matrix(~ 0 + data$condition)
colnames(design) <- make.names(colnames(design))
cont_mat <- makeContrasts(
  NFT_CTRL =
    data.conditionPos -
    data.conditionNeg,
  levels = design
)

corr <- duplicateCorrelation(assay(data), design, block = data$donor)
fit <- lmFit(
  assay(data), design,
  correlation = corr$consensus.correlation, block = data$donor
)
fit <- contrasts.fit(fit, cont_mat)
fit <- eBayes(fit, trend = TRUE, robust = TRUE)
plotSA(fit)

data_corrected <- removeBatchEffect(
  assay(data), group = data$condition,
  correlation = corr$consensus.correlation, block = data$donor
)

tests <- decideTests(fit, method = "global")
tc <- textConnection("results", open = "w")
write.fit(
  fit, tests, file = tc,
  adjust = "BH", F.adjust = "BH", method = "global"
)
close(tc)
results <- read.delim(text = results)
```

# References

This is the concluding section of the document, where we output the `sessionInfo`, and create a bibliography for works cited.

```{r}
sessionInfo()
```
